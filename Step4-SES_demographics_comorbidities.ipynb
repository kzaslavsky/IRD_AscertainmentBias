{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to test effect of demographics, SES, and comorbidities on probability of being annotated with a diagnosis\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# Get the BigQuery curated dataset for the current workspace context.\n",
    "CDR = os.environ['WORKSPACE_CDR']\n",
    "\n",
    "from google.cloud import bigquery\n",
    "# Instantiate a BigQuery client\n",
    "client = bigquery.Client()\n",
    "#!pip install upsetplot #if necessary\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.max_row', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be75691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTable(table_name, folder):\n",
    "    \"\"\"\n",
    "    Purpose: Download TSV from gs://<WORKSPACE_BUCKET>/data/<folder>/ and load as DataFrame (tab-delimited).\n",
    "    Inputs: table_name (str), folder (str).\n",
    "    Returns: pandas DataFrame.\n",
    "    \"\"\"\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{folder}/{table_name}' .\")\n",
    "\n",
    "    print(f'[INFO] {table_name} is successfully downloaded into your working space')\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    table_read = pd.read_csv(table_name, sep=\"\\t\")\n",
    "    return table_read\n",
    "def getFile(table_name, folder):\n",
    "    \"\"\"\n",
    "    Purpose: Download a file from gs://<WORKSPACE_BUCKET>/data/<folder>/ into the working directory.\n",
    "    \"\"\"\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{folder}/{table_name}' .\")\n",
    "\n",
    "    print(f'[INFO] {table_name} is successfully downloaded into your working space')\n",
    "def saveToBucket(df, df_filename, data_folder):\n",
    "    \"\"\"\n",
    "    Purpose: Save DataFrame as TSV and upload to GCS under data/<data_folder>/ using gsutil.\n",
    "    Inputs: df (DataFrame), df_filename (str), data_folder (str). Requires WORKSPACE_BUCKET.\n",
    "    \"\"\"\n",
    "    df.to_csv(df_filename, sep = \"\\t\", index=False)\n",
    "\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file to the bucket\n",
    "    args = [\"gsutil\", \"cp\", f\"./{df_filename}\", f\"{my_bucket}/data/{data_folder}/\"]\n",
    "    output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "    # print output from gsutil\n",
    "    output.stderr\n",
    "def widen_comorbidity(pID_cond_table):\n",
    "    \"\"\"\n",
    "    Purpose: Map ICD codes to comorbidity categories and pivot to a wide one-hot matrix by person_id.\n",
    "    Inputs: pID_cond_table with columns person_id and source_concept_code.\n",
    "    Returns: Wide DataFrame with standardized binary comorbidity columns.\n",
    "    \"\"\"\n",
    "    pID_cond_table['comorbidities'] = pID_cond_table['source_concept_code'].apply(assign_comorbidity)\n",
    "    \n",
    "    std_cols = [\n",
    "        \"comorbidities_hemonc\",\n",
    "        \"comorbidities_DM\",\n",
    "        \"cmspec_DM_microvascular\",\n",
    "        \"comorbidities_vitAdef\",\n",
    "        \"comordbities_obesity\",\n",
    "        \"comordbities_rare\",\n",
    "        \"comordbities_neuropsych\",\n",
    "        \"comordbities_ent\",\n",
    "        \"comordbities_circulatory\",\n",
    "        \"comordbities_HTN\",\n",
    "        \"comordbities_ischemicHD\",\n",
    "        \"comorb_GI_skin_MSK_GU\",\n",
    "        \"comordbities_congenital\",\n",
    "        \"comordbities_dactyly\",\n",
    "        \"comordbities_external\",\n",
    "        \"comorbidities_HLD\"\n",
    "    ]\n",
    "    \n",
    "    wide = pd.crosstab(pID_cond_table['person_id'], pID_cond_table['comorbidities']).reset_index()\n",
    "    \n",
    "    # Ensure all standardized columns are present; if a column is missing, create it with zeros.\n",
    "    for col in std_cols:\n",
    "        if col not in wide.columns:\n",
    "            wide[col] = 0\n",
    "\n",
    "    # Reorder the columns: person_id first, then standardized comorbidity columns\n",
    "    wide = wide[['person_id'] + std_cols]\n",
    "\n",
    "\n",
    "    # Convert counts to binary flags: set to 1 if count is at least 1, else 0.\n",
    "    for col in std_cols:\n",
    "        wide[col] = wide[col].apply(lambda x: 1 if x >= 1 else 0)\n",
    "        \n",
    "    return wide\n",
    "def assign_comorbidity(code):\n",
    "    \n",
    "    if code in icd9_map:\n",
    "        return icd9_map[code]\n",
    "    \"\"\"\n",
    "    Given an ICD10CM code, assign a comorbidity category based on the following scheme:\n",
    "    \n",
    "    - If code is in E08-E13, assign \"comorbidities_DM\". But if the decimal part (if present)\n",
    "      is between 0.2 and 0.5 then assign \"cmspec_DM_microvascular\".\n",
    "    - If code starts with E50 exactly, assign \"comordbities_vitAdef\".\n",
    "    - If code is in E65-E68, assign \"comordbities_obesity\".\n",
    "    - If code is in E70-E75, assign \"comordbities_rare\".\n",
    "    - If code starts with F or G, assign \"comordbities_neuropsych\".\n",
    "    - If code is in H60-H95, assign \"comordbities_ent\".\n",
    "    - If code starts with I, assign \"comordbities_circulatory\". However, if the numeric part is:\n",
    "        - 10 to 15 → \"comordbities_HTN\"\n",
    "        - 20 to 25 → \"comordbities_ischemicHD\"\n",
    "    - If code starts with K, L, M, or N, assign \"comorb_GI_skin_MSK_GU\".\n",
    "    - If code starts with Q, assign \"comordbities_congenital\". However, if the numeric part is\n",
    "      between 69 and 74, then assign \"comordbities_dactyly\".\n",
    "    - If code starts with any letter from T through Z, assign \"comordbities_external\".\n",
    "    \n",
    "    Note: This example assumes that the code format is a letter followed by two digits,\n",
    "    optionally followed by a decimal and additional digits.\n",
    "    \"\"\"\n",
    "    # Use regex to extract the letter and the first two digits\n",
    "    match = re.match(r\"([A-Z])(\\d{2})(?:\\.(\\d+))?\", code)\n",
    "    if not match:\n",
    "        return None  # or return code if format is unexpected\n",
    "\n",
    "    letter, digits, dec = match.groups()\n",
    "    num = int(digits)\n",
    "\n",
    "    # 1. E08-E13 with potential subcategory check on the decimal part\n",
    "    if letter == 'E' and 8 <= num <= 13:\n",
    "        '''        if dec is not None:\n",
    "            try:\n",
    "                dec_val = float(\"0.\" + dec)\n",
    "                # if the decimal part is between 0.2 and 0.5, assign the microvascular specification\n",
    "                if 0.2 <= dec_val <= 0.5:\n",
    "                    return \"cmspec_DM_microvascular\"\n",
    "            except ValueError:\n",
    "                pass'''\n",
    "        return \"comorbidities_DM\"\n",
    "    \n",
    "    # 2. E50 exactly → vitamin A deficiency\n",
    "    if code.startswith(\"E50\"):\n",
    "        return \"comordbities_vitAdef\"\n",
    "    \n",
    "    # 3. E65-E68 → obesity\n",
    "    if letter == 'E' and 65 <= num <= 68:\n",
    "        return \"comordbities_obesity\"\n",
    "    \n",
    "    # 4. E70-E75 → rare\n",
    "    if letter == 'E' and 70 <= num <= 75:\n",
    "        return \"comordbities_rare\"\n",
    "    \n",
    "    # 4. E78 → hypercholesterolemia\n",
    "    if letter == 'E' and num == 78:\n",
    "        return \"comorbidities_HLD\"\n",
    "    \n",
    "    # 5. F or G → neuropsych\n",
    "    if letter in ['F', 'G']:\n",
    "        return \"comordbities_neuropsych\"\n",
    "    \n",
    "    # 6. H60-H95 → ENT disorders\n",
    "    if letter == 'H' and 60 <= num <= 95:\n",
    "        return \"comordbities_ent\"\n",
    "    \n",
    "    # 7. I codes: default circulatory; with subcategories for HTN and ischemicHD\n",
    "    if letter == 'I':\n",
    "        if 10 <= num <= 15:\n",
    "            return \"comordbities_HTN\"\n",
    "        elif 20 <= num <= 25:\n",
    "            return \"comordbities_ischemicHD\"\n",
    "        else:\n",
    "            return \"comordbities_circulatory\"\n",
    "    \n",
    "    # 8. K, L, M, N → GI, skin, MSK, GU\n",
    "    if letter in ['K', 'L', 'M', 'N']:\n",
    "        return \"comorb_GI_skin_MSK_GU\"\n",
    "    \n",
    "    # 9. Q codes: default congenital; with subcategory for dactyly\n",
    "    if letter == 'Q':\n",
    "        if 69 <= num <= 74:\n",
    "            return \"comordbities_dactyly\"\n",
    "        else:\n",
    "            return \"comordbities_congenital\"\n",
    "    \n",
    "    # 10. T through Z → external\n",
    "    if letter >= 'T' and letter <= 'Z':\n",
    "        return \"comordbities_external\"\n",
    "    \n",
    "    if letter == 'S':\n",
    "        return \"comordbities_external\"\n",
    "    \n",
    "    if letter in ['C', 'D']:\n",
    "        return \"comorbidities_hemonc\"\n",
    "    \n",
    "    # If none of the conditions match, return None or a default category\n",
    "    return None\n",
    "def pID_mobidity_master(pid_var_con_table):\n",
    "    \"\"\"\n",
    "    Purpose: Build condition occurrence table (ICD9/10 only) for given people, annotate comorbidities, and produce wide+long outputs.\n",
    "    Inputs: pid_var_con_table with person_id.\n",
    "    Returns: [wide_comorbidity_df, ds_occurrenceICD].\n",
    "    \"\"\"\n",
    "    personid_list =  ','.join(map(str, pid_var_con_table[\"person_id\"].tolist()))\n",
    "\n",
    "    ds_occurrence = pd.read_gbq(f'''\n",
    "    SELECT\n",
    "        dsc.*,\n",
    "        c.*\n",
    "    FROM\n",
    "        `{CDR}.ds_condition_occurrence` dsc\n",
    "        JOIN `{CDR}.concept` c on c.concept_id = dsc.condition_concept_id\n",
    "\n",
    "    WHERE\n",
    "        person_id IN ({personid_list})\n",
    "        #AND dsc.ds_sleep_level IN (1585375, 1585370)\n",
    "\n",
    "\n",
    "    ''',  progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    ds_occurrence.columns = ds_occurrence.columns.str.lower()\n",
    "    ds_occurrenceICD = ds_occurrence[ds_occurrence[\"source_vocabulary\"].isin([\"ICD10CM\", \"ICD9CM\"])]\n",
    "    ds_occurrenceICD['comorbidities'] = ds_occurrenceICD['source_concept_code'].apply(assign_comorbidity)\n",
    "\n",
    "    ds_occurrence_minimal = ds_occurrenceICD[[\"person_id\", \"source_concept_code\", \"comorbidities\"]]   \n",
    "    wide = widen_comorbidity(ds_occurrence_minimal)\n",
    "    \n",
    "    return [wide, ds_occurrenceICD]\n",
    "def assign_LS_smoke(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Dont Know\" in answer_SES or \"Skip\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"No\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Yes\" in answer_SES:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_married(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES or \"Other Arrangement\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"Separated\" in answer_SES or \"Widowed\" in answer_SES or \"Divorced\" in answer_SES or \"Never Married\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Married\" in answer_SES or \"Living With Partner\" in answer_SES:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "def pID_survey_master(pid_var_con_table):\n",
    "    personid_list =  ','.join(map(str, pid_var_con_table[\"person_id\"].tolist()))\n",
    "\n",
    "    pid_survey = pd.read_gbq(f'''\n",
    "    SELECT\n",
    "        dsc.*\n",
    "    FROM\n",
    "        `{CDR}.ds_survey` dsc\n",
    "        #JOIN `{CDR}.concept` c on c.concept_id = dsc.condition_concept_id\n",
    "\n",
    "    WHERE\n",
    "        person_id IN ({personid_list})\n",
    "        #AND dsc.ds_sleep_level IN (1585375, 1585370)\n",
    "\n",
    "\n",
    "    ''',  progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    pid_survey.columns = pid_survey.columns.str.lower()\n",
    "    \n",
    "    #assign values to questions\n",
    "    pid_survey['SES_education'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585940][\"answer\"].apply(assign_SES_education)\n",
    "    pid_survey['SES_income'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585375][\"answer\"].apply(assign_SES_income)\n",
    "    pid_survey['SES_healthins'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585386][\"answer\"].apply(assign_SES_healthins)\n",
    "    pid_survey['SES_homeown'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585370][\"answer\"].apply(assign_SES_homeown)\n",
    "    pid_survey['SES_married'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585892][\"answer\"].apply(assign_SES_married)\n",
    "    pid_survey['LS_smoke'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585857][\"answer\"].apply(assign_LS_smoke)\n",
    "    \n",
    "    #make one wide table\n",
    "    out_table = pid_survey[pid_survey[\"question_concept_id\"] == 1585940][[\"person_id\", \"SES_education\"]].drop_duplicates()\n",
    "    out_table_inc = pid_survey[pid_survey[\"question_concept_id\"] == 1585375][[\"person_id\", \"SES_income\"]].drop_duplicates()\n",
    "    out_table_hi = pid_survey[pid_survey[\"question_concept_id\"] == 1585386][[\"person_id\", \"SES_healthins\"]].drop_duplicates()\n",
    "    out_table_home = pid_survey[pid_survey[\"question_concept_id\"] == 1585370][[\"person_id\", \"SES_homeown\"]].drop_duplicates()\n",
    "    out_table_married = pid_survey[pid_survey[\"question_concept_id\"] == 1585892][[\"person_id\", \"SES_married\"]].drop_duplicates()\n",
    "    out_table_LS_smoke = pid_survey[pid_survey[\"question_concept_id\"] == 1585857][[\"person_id\", \"LS_smoke\"]].drop_duplicates()\n",
    "    \n",
    "    #merge tables\n",
    "    out_table = pd.merge(out_table, out_table_inc, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_hi, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_home, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_married, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_LS_smoke, on = \"person_id\", how = \"left\")\n",
    "\n",
    "    \n",
    "    #return [wide, ds_occurrenceICD10]\n",
    "    return [out_table, pid_survey]\n",
    "def assign_SES_healthins(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES or \"Dont Know\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"Yes\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"No\" in answer_SES:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_education(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"One Through Four\" in answer_SES or \"Five Through Eight\" in answer_SES or \"Nine Through Eleven\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Twelve Or GED\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"College One to Three\" in answer_SES:\n",
    "        return 2\n",
    "    elif \"College Graduate\" in answer_SES:\n",
    "        return 3\n",
    "    elif \"Advanced Degree\" in answer_SES:\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_income(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" 1585376,  → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"less 10k\" in answer_SES or \"10k 25k\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"25k 35k\" in answer_SES or \"35k 50k\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"50k 75k\" in answer_SES or \"75k 100k\" in answer_SES:\n",
    "        return 2\n",
    "    elif \"100k 150k\" in answer_SES or \"150k 200k\" in answer_SES:\n",
    "        return 3\n",
    "    elif \"more 200k\" in answer_SES:\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_homeown(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "\n",
    "    if \"Current Home Own: Own\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"Current Home Own: Rent\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Current Home Own: Other Arrangement\" in answer_SES:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in files\n",
    "\n",
    "ALL_IRD = getTable(\"ALL_IRD_raceproc.tsv\", \"personID_variant\")\n",
    "in_retdys = getTable(\"in_retdys.tsv\", \"personID_variant_concept\")\n",
    "notin_retdys = getTable(\"notin_retdys.tsv\", \"personID_variant_concept\")\n",
    "\n",
    "in_retdegen = getTable(\"in_retdegen.tsv\", \"personID_variant_concept\")\n",
    "notin_retdegen = getTable(\"notin_retdegen.tsv\", \"personID_variant_concept\")\n",
    "\n",
    "in_screenretdys = getTable(\"in_screenretdys.tsv\", \"personID_variant_concept\")\n",
    "notin_screenretdys = getTable(\"notin_screenretdys.tsv\", \"personID_variant_concept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#within genotype affected vs unaffected comparisons\n",
    "#get morbidities for each table\n",
    "in_retdys_result = pID_mobidity_master(in_retdys)\n",
    "in_retdys_matrix = in_retdys_result[0]\n",
    "in_retdys_full = in_retdys_result[1]\n",
    "in_retdys_full = in_retdys_full[~in_retdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "\n",
    "notin_retdys_result = pID_mobidity_master(notin_retdys)\n",
    "notin_retdys_matrix = notin_retdys_result[0]\n",
    "notin_retdys_full = notin_retdys_result[1]\n",
    "notin_retdys_full = notin_retdys_full[~notin_retdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "in_retdegen_result = pID_mobidity_master(in_retdegen)\n",
    "in_retdegen_matrix = in_retdegen_result[0]\n",
    "in_retdegen_full = in_retdegen_result[1]\n",
    "in_retdegen_full = in_retdegen_full[~in_retdegen_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "notin_retdegen_result = pID_mobidity_master(notin_retdegen)\n",
    "notin_retdegen_matrix = notin_retdegen_result[0]\n",
    "notin_retdegen_full = notin_retdegen_result[1]\n",
    "notin_retdegen_full = notin_retdegen_full[~notin_retdegen_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "in_screenretdys_result = pID_mobidity_master(in_screenretdys)\n",
    "in_screenretdys_matrix = in_screenretdys_result[0]\n",
    "in_screenretdys_full = in_screenretdys_result[1]\n",
    "in_screenretdys_full = in_screenretdys_full[~in_screenretdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "notin_screenretdys_result = pID_mobidity_master(notin_screenretdys)\n",
    "notin_screenretdys_matrix = notin_screenretdys_result[0]\n",
    "notin_screenretdys_full = notin_screenretdys_result[1]\n",
    "notin_screenretdys_full = notin_screenretdys_full[~notin_screenretdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate number of visits for each person\n",
    "def countVisits(matrix, df_visits):\n",
    "    \"\"\"\n",
    "    Purpose: Count number of condition visits per person and merge as 'NumberOfVisits'.\n",
    "    Inputs: matrix (DataFrame with person_id), df_visits (long table with condition_start_datetime).\n",
    "    Returns: matrix with added NumberOfVisits column.\n",
    "    \"\"\"\n",
    "    visit_counts = (\n",
    "        df_visits\n",
    "        .groupby('person_id')['condition_start_datetime']\n",
    "        .size()\n",
    "        .reset_index(name='NumberOfVisits')\n",
    "    )\n",
    "    merged_matrix = pd.merge(matrix, visit_counts, on = \"person_id\", how = \"right\")\n",
    "    \n",
    "    return(merged_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e227ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_retdys_matrix = countVisits(in_retdys_matrix, in_retdys_full)\n",
    "in_retdegen_matrix = countVisits(in_retdegen_matrix, in_retdegen_full)\n",
    "in_screenretdys_matrix = countVisits(in_screenretdys_matrix, in_screenretdys_full)\n",
    "notin_retdys_matrix = countVisits(notin_retdys_matrix, notin_retdys_full)\n",
    "notin_retdegen_matrix = countVisits(notin_retdegen_matrix, notin_retdegen_full)\n",
    "notin_screenretdys_matrix = countVisits(notin_screenretdys_matrix, notin_screenretdys_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b42f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey data and SES\n",
    "in_retdys_survey = pID_survey_master(in_retdys)\n",
    "in_retdys_survey_matrix = in_retdys_survey[0]\n",
    "in_retdys_survey_full = in_retdys_survey[1]\n",
    "notin_retdys_survey = pID_survey_master(notin_retdys)\n",
    "notin_retdys_survey_matrix = notin_retdys_survey[0]\n",
    "notin_retdys_survey_full = notin_retdys_survey[1]\n",
    "\n",
    "in_retdegen_survey = pID_survey_master(in_retdegen)\n",
    "in_retdegen_survey_matrix = in_retdegen_survey[0]\n",
    "in_retdegen_survey_full = in_retdegen_survey[1]\n",
    "notin_retdegen_survey = pID_survey_master(notin_retdegen)\n",
    "notin_retdegen_survey_matrix = notin_retdegen_survey[0]\n",
    "notin_retdegen_survey_full = notin_retdegen_survey[1]\n",
    "\n",
    "in_screenretdys_survey = pID_survey_master(in_screenretdys)\n",
    "in_screenretdys_survey_matrix = in_screenretdys_survey[0]\n",
    "in_screenretdys_survey_full = in_screenretdys_survey[1]\n",
    "notin_screenretdys_survey = pID_survey_master(notin_screenretdys)\n",
    "notin_screenretdys_survey_matrix = notin_screenretdys_survey[0]\n",
    "notin_screenretdys_survey_full = notin_screenretdys_survey[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to merge survey/SES and morbidity data\n",
    "def mergeSurveyforAnno(matrix, source_df):\n",
    "    \"\"\"\n",
    "    Purpose: Mark affected=\"Yes\" and attach Age (from AgeAtVisit_Years), Sex, and race from source_df.\n",
    "    Returns: merged DataFrame with standardized 'Age' and 'Sex' columns.\n",
    "    \"\"\"\n",
    "    matrix[\"affected\"] = \"Yes\"\n",
    "    matrix = pd.merge(matrix, source_df[[\"person_id\", \"AgeAtVisit_Years\", \"sex_at_birth_source_value\", \"race\"]],\n",
    "                                      on=\"person_id\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "    matrix = matrix.rename(columns={'AgeAtVisit_Years': 'Age',\n",
    "                                                                 'sex_at_birth_source_value': \"Sex\"})\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def mergeSurveyforUNAnno(matrix, source_df):\n",
    "    \"\"\"\n",
    "    Purpose: Mark affected=\"No\" and attach Age (from AgeAtConsent_Years), Sex, and race from source_df.\n",
    "    Returns: merged DataFrame with standardized 'Age' and 'Sex' columns.\n",
    "    \"\"\"\n",
    "    matrix[\"affected\"] = \"No\"\n",
    "    matrix = pd.merge(matrix, source_df[[\"person_id\", \"AgeAtConsent_Years\", \"sex_at_birth_source_value\", \"race\"]],\n",
    "                                      on=\"person_id\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "    matrix = matrix.rename(columns={'AgeAtConsent_Years': 'Age',\n",
    "                                                                 'sex_at_birth_source_value': \"Sex\"})\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d258cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge survey/SES and morbidity data\n",
    "in_retdys_survey_matrix = mergeSurveyforAnno(in_retdys_survey[0], in_retdys)\n",
    "notin_retdys_survey_matrix = mergeSurveyforUNAnno(notin_retdys_survey[0], notin_retdys)\n",
    "in_retdegen_survey_matrix = mergeSurveyforAnno(in_retdegen_survey[0], in_retdegen)\n",
    "notin_retdegen_survey_matrix = mergeSurveyforUNAnno(notin_retdegen_survey[0], notin_retdegen)\n",
    "in_screenretdys_survey_matrix = mergeSurveyforAnno(in_screenretdys_survey[0], in_screenretdys)\n",
    "notin_screenretdys_survey_matrix = mergeSurveyforUNAnno(notin_screenretdys_survey[0], notin_screenretdys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare for logistic regression models\n",
    "\n",
    "#drop person_id\n",
    "retdys_matrix_merge_glmnet = retdys_matrix_merge.drop(\"person_id\", axis = 1)\n",
    "retdegen_matrix_merge_glmnet = retdegen_matrix_merge.drop(\"person_id\", axis = 1)\n",
    "screenretdys_matrix_merge_glmnet = screenretdys_matrix_merge.drop(\"person_id\", axis = 1)\n",
    "\n",
    "def makeSexNumeric(df):\n",
    "    \"\"\"\n",
    "    Purpose: Map categorical Sex (SexAtBirth_*) to numeric 0/1 as 'sex_numeric' and drop 'Sex'.\n",
    "    Returns: DataFrame with numeric sex feature.\n",
    "    \"\"\"\n",
    "    sex_map = {\n",
    "        'SexAtBirth_Female': 0,\n",
    "        'SexAtBirth_Male':   1\n",
    "    }\n",
    "    \n",
    "    df['sex_numeric'] = df['Sex'].map(sex_map)\n",
    "    df['sex_numeric'] = df['sex_numeric'].astype(float)\n",
    "    df = df.drop(\"Sex\", axis = 1)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "retdys_matrix_merge_glmnet = makeSexNumeric(retdys_matrix_merge_glmnet)\n",
    "retdegen_matrix_merge_glmnet = makeSexNumeric(retdegen_matrix_merge_glmnet)\n",
    "screenretdys_matrix_merge_glmnet = makeSexNumeric(screenretdys_matrix_merge_glmnet)\n",
    "\n",
    "def dummyRace(df):\n",
    "    \"\"\"\n",
    "    Purpose: One-hot encode 'race' column (drop_first=True).\n",
    "    Returns: DataFrame with race dummies.\n",
    "    \"\"\"\n",
    "    df = pd.get_dummies(df, columns=['race'], drop_first=True)\n",
    "    return df\n",
    "\n",
    "retdys_matrix_merge_glmnet = dummyRace(retdys_matrix_merge_glmnet)\n",
    "retdegen_matrix_merge_glmnet = dummyRace(retdegen_matrix_merge_glmnet)\n",
    "screenretdys_matrix_merge_glmnet = dummyRace(screenretdys_matrix_merge_glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do both univariate and multivariate at once\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# --- your helpers (unchanged) ---\n",
    "def bin_outcome(df):    \n",
    "    df['outcome_bin'] = df['affected'].map({'Yes': 1, 'No': 0})\n",
    "    return df\n",
    "\n",
    "def divideNumVisit(df, amt = 10):\n",
    "    if \"NumberOfVisits\" in df.columns:\n",
    "        df[\"NumberOfVisits\"] = df[\"NumberOfVisits\"] / amt\n",
    "    return df\n",
    "\n",
    "def divideAge(df, amt = 1):\n",
    "    if \"Age\" in df.columns:\n",
    "        df[\"Age\"] = df[\"Age\"] / amt\n",
    "    return df\n",
    "\n",
    "# --- internal utility ---\n",
    "def _fit_logit(y, X):\n",
    "    \"\"\"Fit Logit with intercept, return (model, result) or (None, None) if it fails.\"\"\"\n",
    "    try:\n",
    "        X = sm.add_constant(X, has_constant='add')\n",
    "        model = sm.Logit(y, X)\n",
    "        res = model.fit(disp=False)\n",
    "        return model, res\n",
    "    except (PerfectSeparationError, np.linalg.LinAlgError, ValueError, ZeroDivisionError, FloatingPointError):\n",
    "        return None, None\n",
    "\n",
    "def _tidy_res(res, var_name):\n",
    "    \"\"\"Extract OR, CI, p for var_name from a LogitResults; return NaNs if not available.\"\"\"\n",
    "    if res is None:\n",
    "        return dict(OR=np.nan, lo=np.nan, hi=np.nan, p=np.nan)\n",
    "    try:\n",
    "        summ = res.summary2().tables[1]\n",
    "        if var_name not in summ.index:\n",
    "            return dict(OR=np.nan, lo=np.nan, hi=np.nan, p=np.nan)\n",
    "        coef = summ.loc[var_name, 'Coef.']\n",
    "        lo   = summ.loc[var_name, '[0.025']\n",
    "        hi   = summ.loc[var_name, '0.975]']\n",
    "        p    = summ.loc[var_name, 'P>|z|']\n",
    "        return dict(OR=float(np.exp(coef)),\n",
    "                    lo=float(np.exp(lo)),\n",
    "                    hi=float(np.exp(hi)),\n",
    "                    p=float(p))\n",
    "    except Exception:\n",
    "        return dict(OR=np.nan, lo=np.nan, hi=np.nan, p=np.nan)\n",
    "\n",
    "def doLogit_both(df,\n",
    "                 drop_cols=None,\n",
    "                 visits_divisor=10,\n",
    "                 age_divisor=1,\n",
    "                 compute_vif=False):\n",
    "    \"\"\"\n",
    "    Multivariate: use all predictors not in drop_cols (rows = complete cases across all).\n",
    "    Univariate: for each predictor, RELOAD the full df and drop NaNs only for that predictor + outcome.\n",
    "    Returns:\n",
    "      {\n",
    "        \"multi\": (multi_model, multi_res, X_multi, y_multi),\n",
    "        \"uni\": {var: (model, res)},\n",
    "        \"combined_table\": 9-col DataFrame,\n",
    "        \"vif\": DataFrame or None\n",
    "      }\n",
    "    \"\"\"\n",
    "    df_full = df.copy()\n",
    "\n",
    "    # Prepare the full outcome\n",
    "    if 'outcome_bin' not in df_full.columns:\n",
    "        raise ValueError(\"df must contain 'outcome_bin'; run bin_outcome first.\")\n",
    "    y_full = df_full['outcome_bin'].astype(float)\n",
    "\n",
    "    # ---------- MULTIVARIATE ----------\n",
    "    # Build X from full df, then drop requested columns\n",
    "    X_multi = df_full.drop(columns=['affected', 'outcome_bin'], errors='ignore')\n",
    "    if drop_cols:\n",
    "        X_multi = X_multi.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # Coerce numeric and clean\n",
    "    X_multi = X_multi.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "    X_multi = X_multi.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Optional scaling\n",
    "    X_multi = divideNumVisit(X_multi, amt=visits_divisor)\n",
    "    X_multi = divideAge(X_multi, amt=age_divisor)\n",
    "\n",
    "    # Keep only complete cases across all multivariate predictors + outcome\n",
    "    data_multi = pd.concat([X_multi, y_full], axis=1).dropna()\n",
    "    if data_multi.empty:\n",
    "        raise ValueError(\"No rows left for multivariate fit after NaN cleaning.\")\n",
    "    X_multi_cc = data_multi[X_multi.columns]\n",
    "    y_multi_cc = data_multi[y_full.name]\n",
    "\n",
    "    multi_model, multi_res = _fit_logit(y_multi_cc, X_multi_cc)\n",
    "\n",
    "    # ---------- UNIVARIATE (reload df for each predictor) ----------\n",
    "    uni = {}\n",
    "    predictors = list(X_multi.columns)  # univariates on the same set you planned to use multivariately\n",
    "    for var in predictors:\n",
    "        # take ONLY this predictor from the full df (not multivariate CC)\n",
    "        X_uni = df_full[[var]].copy()\n",
    "\n",
    "        # numeric conversion & clean for this var alone\n",
    "        X_uni[var] = pd.to_numeric(X_uni[var], errors='coerce').astype(float)\n",
    "        X_uni[var] = X_uni[var].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        # scaling if it's Age or NumberOfVisits (safe no-op otherwise)\n",
    "        if var == \"NumberOfVisits\":\n",
    "            X_uni = divideNumVisit(X_uni, amt=visits_divisor)\n",
    "        if var == \"Age\":\n",
    "            X_uni = divideAge(X_uni, amt=age_divisor)\n",
    "\n",
    "        # drop NaNs only in this var + outcome\n",
    "        data_uni = pd.concat([X_uni, y_full], axis=1).dropna()\n",
    "        if data_uni.empty:\n",
    "            uni[var] = (None, None)\n",
    "            continue\n",
    "\n",
    "        Xu = data_uni[[var]]\n",
    "        yu = data_uni[y_full.name]\n",
    "        uni[var] = _fit_logit(yu, Xu)\n",
    "\n",
    "    # ---------- Optional VIF (on multivariate design) ----------\n",
    "    vif_df = None\n",
    "    if compute_vif and multi_res is not None and X_multi_cc.shape[1] > 1:\n",
    "        X_for_vif = sm.add_constant(X_multi_cc, has_constant='add')\n",
    "        X_no_const = X_for_vif.drop(columns=['const'], errors='ignore')\n",
    "        vif_df = pd.DataFrame({\n",
    "            \"feature\": X_no_const.columns,\n",
    "            \"VIF\": [variance_inflation_factor(X_no_const.values, i)\n",
    "                    for i in range(X_no_const.shape[1])]\n",
    "        })\n",
    "\n",
    "    # ---------- Build the 9-column combined table ----------\n",
    "    rows = []\n",
    "    for var in predictors:\n",
    "        u_model, u_res = uni[var]\n",
    "        u = _tidy_res(u_res, var)\n",
    "        m = _tidy_res(multi_res, var)\n",
    "        rows.append({\n",
    "            \"variable\": var,\n",
    "            \"uni_OR\": u['OR'],\n",
    "            \"uni_CI_lo\": u['lo'],\n",
    "            \"uni_CI_hi\": u['hi'],\n",
    "            \"uni_p\": u['p'],\n",
    "            \"multi_OR\": m['OR'],\n",
    "            \"multi_CI_lo\": m['lo'],\n",
    "            \"multi_CI_hi\": m['hi'],\n",
    "            \"multi_p\": m['p'],\n",
    "        })\n",
    "\n",
    "    combined = pd.DataFrame(rows).sort_values(\n",
    "        by=[\"multi_p\", \"uni_p\"], na_position=\"last\"\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return {\n",
    "        \"multi\": (multi_model, multi_res, X_multi_cc, y_multi_cc),\n",
    "        \"uni\": uni,\n",
    "        \"combined_table\": combined,\n",
    "        \"vif\": vif_df\n",
    "    }\n",
    "\n",
    "def tidy_logit_result_both(results_dict, html_path=None, float_fmt=\"{:0.5f}\"):\n",
    "    \"\"\"\n",
    "    Pretty-print the 9-col table from doLogit_both. Returns (df, html_str).\n",
    "    \"\"\"\n",
    "    df = results_dict[\"combined_table\"].copy()\n",
    "    num_cols = [\"uni_OR\",\"uni_CI_lo\",\"uni_CI_hi\",\"uni_p\",\n",
    "                \"multi_OR\",\"multi_CI_lo\",\"multi_CI_hi\",\"multi_p\"]\n",
    "    for c in num_cols:\n",
    "        df[c] = df[c].map(lambda x: \"\" if pd.isna(x) else float_fmt.format(x))\n",
    "    html = df.to_html(index=False, border=0, escape=False)\n",
    "    if html_path:\n",
    "        with open(html_path, \"w\") as f:\n",
    "            f.write(html)\n",
    "    return df, html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns you want gone before modeling:\n",
    "# commented - keep\n",
    "# uncommented - drop\n",
    "to_drop = [\n",
    "    'comorbidities_vitAdef',\n",
    "    'comorb_GI_skin_MSK_GU',\n",
    "\n",
    "    'comordbities_dactyly',\n",
    "    'comordbities_external',\n",
    "    'comordbities_congenital',\n",
    "    'comordbities_neuropsych',\n",
    "    'comordbities_ent',\n",
    "    'comordbities_rare',\n",
    "    'cmspec_DM_microvascular',\n",
    "    'comordbities_circulatory',\n",
    "    'comordbities_ischemicHD',\n",
    "    'comorbidities_hemonc',\n",
    "    'race_WhatRaceEthnicity_Black',\n",
    "    'race_Unknown',\n",
    "    'race_WhatRaceEthnicity_AIAN',\n",
    "    'race_WhatRaceEthnicity_MENA',\n",
    "    'race_WhatRaceEthnicity_White',\n",
    "    #'SES_education',\n",
    "    'SES_income',\n",
    "    'SES_homeown',\n",
    "    'SES_healthins',\n",
    "    'SES_married',\n",
    "    #'comorbidities_DM',\n",
    "    'comordbities_obesity',\n",
    "    'comordbities_HTN',\n",
    "    'comorbidities_HLD',\n",
    "    #'LS_smoke',\n",
    "    #'NumberOfVisits',\n",
    "    #'sex_numeric',\n",
    "    'race_WhatRaceEthnicity_Asian'\n",
    "    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do both univariate and multivariate and output as single HTML table - change table names as needed\n",
    "res = doLogit_both(\n",
    "    retdys_matrix_merge_glmnet,\n",
    "    drop_cols=to_drop,\n",
    "    visits_divisor=100,\n",
    "    age_divisor=10,\n",
    "    compute_vif=True  # optional\n",
    ")\n",
    "\n",
    "#Get the 9-column tidy table (and optional HTML)\n",
    "table9, html_str = tidy_logit_result_both(res, html_path=\"table_retdys_both.html\")\n",
    "\n",
    "#Access fitted models if you need detailed summaries:\n",
    "multi_model, multi_res, X_multi, y = res[\"multi\"]\n",
    "print(multi_res.summary())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
