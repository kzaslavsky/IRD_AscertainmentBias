{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to test effect of demographics, SES, and comorbidities on probability of being annotated with a diagnosis\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# Get the BigQuery curated dataset for the current workspace context.\n",
    "CDR = os.environ['WORKSPACE_CDR']\n",
    "\n",
    "from google.cloud import bigquery\n",
    "# Instantiate a BigQuery client\n",
    "client = bigquery.Client()\n",
    "#!pip install upsetplot #if necessary\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.max_row', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be75691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTable(table_name, folder):\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{folder}/{table_name}' .\")\n",
    "\n",
    "    print(f'[INFO] {table_name} is successfully downloaded into your working space')\n",
    "    # save dataframe in a csv file in the same workspace as the notebook\n",
    "    table_read = pd.read_csv(table_name, sep=\"\\t\")\n",
    "    return table_read\n",
    "def getFile(table_name, folder):\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file from the bucket to the current working space\n",
    "    os.system(f\"gsutil cp '{my_bucket}/data/{folder}/{table_name}' .\")\n",
    "\n",
    "    print(f'[INFO] {table_name} is successfully downloaded into your working space')\n",
    "def saveToBucket(df, df_filename, data_folder):\n",
    "    df.to_csv(df_filename, sep = \"\\t\", index=False)\n",
    "\n",
    "    # get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "    # copy csv file to the bucket\n",
    "    args = [\"gsutil\", \"cp\", f\"./{df_filename}\", f\"{my_bucket}/data/{data_folder}/\"]\n",
    "    output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "    # print output from gsutil\n",
    "    output.stderr\n",
    "def widen_comorbidity(pID_cond_table):\n",
    "    pID_cond_table['comorbidities'] = pID_cond_table['source_concept_code'].apply(assign_comorbidity)\n",
    "    \n",
    "    std_cols = [\n",
    "        \"comorbidities_hemonc\",\n",
    "        \"comorbidities_DM\",\n",
    "        \"cmspec_DM_microvascular\",\n",
    "        \"comorbidities_vitAdef\",\n",
    "        \"comordbities_obesity\",\n",
    "        \"comordbities_rare\",\n",
    "        \"comordbities_neuropsych\",\n",
    "        \"comordbities_ent\",\n",
    "        \"comordbities_circulatory\",\n",
    "        \"comordbities_HTN\",\n",
    "        \"comordbities_ischemicHD\",\n",
    "        \"comorb_GI_skin_MSK_GU\",\n",
    "        \"comordbities_congenital\",\n",
    "        \"comordbities_dactyly\",\n",
    "        \"comordbities_external\",\n",
    "        \"comorbidities_HLD\"\n",
    "    ]\n",
    "    \n",
    "    wide = pd.crosstab(pID_cond_table['person_id'], pID_cond_table['comorbidities']).reset_index()\n",
    "    \n",
    "    # Ensure all standardized columns are present; if a column is missing, create it with zeros.\n",
    "    for col in std_cols:\n",
    "        if col not in wide.columns:\n",
    "            wide[col] = 0\n",
    "\n",
    "    # Reorder the columns: person_id first, then standardized comorbidity columns\n",
    "    wide = wide[['person_id'] + std_cols]\n",
    "\n",
    "\n",
    "    # Convert counts to binary flags: set to 1 if count is at least 1, else 0.\n",
    "    for col in std_cols:\n",
    "        wide[col] = wide[col].apply(lambda x: 1 if x >= 1 else 0)\n",
    "        \n",
    "    return wide\n",
    "def assign_comorbidity(code):\n",
    "    \n",
    "    if code in icd9_map:\n",
    "        return icd9_map[code]\n",
    "    \"\"\"\n",
    "    Given an ICD10CM code, assign a comorbidity category based on the following scheme:\n",
    "    \n",
    "    - If code is in E08-E13, assign \"comorbidities_DM\". But if the decimal part (if present)\n",
    "      is between 0.2 and 0.5 then assign \"cmspec_DM_microvascular\".\n",
    "    - If code starts with E50 exactly, assign \"comordbities_vitAdef\".\n",
    "    - If code is in E65-E68, assign \"comordbities_obesity\".\n",
    "    - If code is in E70-E75, assign \"comordbities_rare\".\n",
    "    - If code starts with F or G, assign \"comordbities_neuropsych\".\n",
    "    - If code is in H60-H95, assign \"comordbities_ent\".\n",
    "    - If code starts with I, assign \"comordbities_circulatory\". However, if the numeric part is:\n",
    "        - 10 to 15 → \"comordbities_HTN\"\n",
    "        - 20 to 25 → \"comordbities_ischemicHD\"\n",
    "    - If code starts with K, L, M, or N, assign \"comorb_GI_skin_MSK_GU\".\n",
    "    - If code starts with Q, assign \"comordbities_congenital\". However, if the numeric part is\n",
    "      between 69 and 74, then assign \"comordbities_dactyly\".\n",
    "    - If code starts with any letter from T through Z, assign \"comordbities_external\".\n",
    "    \n",
    "    Note: This example assumes that the code format is a letter followed by two digits,\n",
    "    optionally followed by a decimal and additional digits.\n",
    "    \"\"\"\n",
    "    # Use regex to extract the letter and the first two digits\n",
    "    match = re.match(r\"([A-Z])(\\d{2})(?:\\.(\\d+))?\", code)\n",
    "    if not match:\n",
    "        return None  # or return code if format is unexpected\n",
    "\n",
    "    letter, digits, dec = match.groups()\n",
    "    num = int(digits)\n",
    "\n",
    "    # 1. E08-E13 with potential subcategory check on the decimal part\n",
    "    if letter == 'E' and 8 <= num <= 13:\n",
    "        '''        if dec is not None:\n",
    "            try:\n",
    "                dec_val = float(\"0.\" + dec)\n",
    "                # if the decimal part is between 0.2 and 0.5, assign the microvascular specification\n",
    "                if 0.2 <= dec_val <= 0.5:\n",
    "                    return \"cmspec_DM_microvascular\"\n",
    "            except ValueError:\n",
    "                pass'''\n",
    "        return \"comorbidities_DM\"\n",
    "    \n",
    "    # 2. E50 exactly → vitamin A deficiency\n",
    "    if code.startswith(\"E50\"):\n",
    "        return \"comordbities_vitAdef\"\n",
    "    \n",
    "    # 3. E65-E68 → obesity\n",
    "    if letter == 'E' and 65 <= num <= 68:\n",
    "        return \"comordbities_obesity\"\n",
    "    \n",
    "    # 4. E70-E75 → rare\n",
    "    if letter == 'E' and 70 <= num <= 75:\n",
    "        return \"comordbities_rare\"\n",
    "    \n",
    "    # 4. E78 → hypercholesterolemia\n",
    "    if letter == 'E' and num == 78:\n",
    "        return \"comorbidities_HLD\"\n",
    "    \n",
    "    # 5. F or G → neuropsych\n",
    "    if letter in ['F', 'G']:\n",
    "        return \"comordbities_neuropsych\"\n",
    "    \n",
    "    # 6. H60-H95 → ENT disorders\n",
    "    if letter == 'H' and 60 <= num <= 95:\n",
    "        return \"comordbities_ent\"\n",
    "    \n",
    "    # 7. I codes: default circulatory; with subcategories for HTN and ischemicHD\n",
    "    if letter == 'I':\n",
    "        if 10 <= num <= 15:\n",
    "            return \"comordbities_HTN\"\n",
    "        elif 20 <= num <= 25:\n",
    "            return \"comordbities_ischemicHD\"\n",
    "        else:\n",
    "            return \"comordbities_circulatory\"\n",
    "    \n",
    "    # 8. K, L, M, N → GI, skin, MSK, GU\n",
    "    if letter in ['K', 'L', 'M', 'N']:\n",
    "        return \"comorb_GI_skin_MSK_GU\"\n",
    "    \n",
    "    # 9. Q codes: default congenital; with subcategory for dactyly\n",
    "    if letter == 'Q':\n",
    "        if 69 <= num <= 74:\n",
    "            return \"comordbities_dactyly\"\n",
    "        else:\n",
    "            return \"comordbities_congenital\"\n",
    "    \n",
    "    # 10. T through Z → external\n",
    "    if letter >= 'T' and letter <= 'Z':\n",
    "        return \"comordbities_external\"\n",
    "    \n",
    "    if letter == 'S':\n",
    "        return \"comordbities_external\"\n",
    "    \n",
    "    if letter in ['C', 'D']:\n",
    "        return \"comorbidities_hemonc\"\n",
    "    \n",
    "    # If none of the conditions match, return None or a default category\n",
    "    return None\n",
    "def pID_mobidity_master(pid_var_con_table):\n",
    "    personid_list =  ','.join(map(str, pid_var_con_table[\"person_id\"].tolist()))\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "    ''',  progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    ds_occurrence.columns = ds_occurrence.columns.str.lower()\n",
    "    ds_occurrenceICD = ds_occurrence[ds_occurrence[\"source_vocabulary\"].isin([\"ICD10CM\", \"ICD9CM\"])]\n",
    "    ds_occurrenceICD['comorbidities'] = ds_occurrenceICD['source_concept_code'].apply(assign_comorbidity)\n",
    "\n",
    "    ds_occurrence_minimal = ds_occurrenceICD[[\"person_id\", \"source_concept_code\", \"comorbidities\"]]   \n",
    "    wide = widen_comorbidity(ds_occurrence_minimal)\n",
    "    \n",
    "    return [wide, ds_occurrenceICD]\n",
    "def assign_LS_smoke(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Dont Know\" in answer_SES or \"Skip\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"No\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Yes\" in answer_SES:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_married(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES or \"Other Arrangement\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"Separated\" in answer_SES or \"Widowed\" in answer_SES or \"Divorced\" in answer_SES or \"Never Married\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Married\" in answer_SES or \"Living With Partner\" in answer_SES:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "def pID_survey_master(pid_var_con_table):\n",
    "    personid_list =  ','.join(map(str, pid_var_con_table[\"person_id\"].tolist()))\n",
    "\n",
    "    pid_survey = pd.read_gbq(f'''\n",
    "    SELECT\n",
    "        dsc.*\n",
    "    FROM\n",
    "        `{CDR}.ds_survey` dsc\n",
    "        #JOIN `{CDR}.concept` c on c.concept_id = dsc.condition_concept_id\n",
    "\n",
    "    WHERE\n",
    "        person_id IN ({personid_list})\n",
    "        #AND dsc.ds_sleep_level IN (1585375, 1585370)\n",
    "\n",
    "\n",
    "    ''',  progress_bar_type=\"tqdm_notebook\")\n",
    "    \n",
    "    pid_survey.columns = pid_survey.columns.str.lower()\n",
    "    \n",
    "    #assign values to questions\n",
    "    pid_survey['SES_education'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585940][\"answer\"].apply(assign_SES_education)\n",
    "    pid_survey['SES_income'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585375][\"answer\"].apply(assign_SES_income)\n",
    "    pid_survey['SES_healthins'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585386][\"answer\"].apply(assign_SES_healthins)\n",
    "    pid_survey['SES_homeown'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585370][\"answer\"].apply(assign_SES_homeown)\n",
    "    pid_survey['SES_married'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585892][\"answer\"].apply(assign_SES_married)\n",
    "    pid_survey['LS_smoke'] = pid_survey[pid_survey[\"question_concept_id\"] == 1585857][\"answer\"].apply(assign_LS_smoke)\n",
    "    \n",
    "    #make one wide table\n",
    "    out_table = pid_survey[pid_survey[\"question_concept_id\"] == 1585940][[\"person_id\", \"SES_education\"]].drop_duplicates()\n",
    "    out_table_inc = pid_survey[pid_survey[\"question_concept_id\"] == 1585375][[\"person_id\", \"SES_income\"]].drop_duplicates()\n",
    "    out_table_hi = pid_survey[pid_survey[\"question_concept_id\"] == 1585386][[\"person_id\", \"SES_healthins\"]].drop_duplicates()\n",
    "    out_table_home = pid_survey[pid_survey[\"question_concept_id\"] == 1585370][[\"person_id\", \"SES_homeown\"]].drop_duplicates()\n",
    "    out_table_married = pid_survey[pid_survey[\"question_concept_id\"] == 1585892][[\"person_id\", \"SES_married\"]].drop_duplicates()\n",
    "    out_table_LS_smoke = pid_survey[pid_survey[\"question_concept_id\"] == 1585857][[\"person_id\", \"LS_smoke\"]].drop_duplicates()\n",
    "    \n",
    "    #merge tables\n",
    "    out_table = pd.merge(out_table, out_table_inc, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_hi, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_home, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_married, on = \"person_id\", how = \"left\")\n",
    "    out_table = pd.merge(out_table, out_table_LS_smoke, on = \"person_id\", how = \"left\")\n",
    "\n",
    "    \n",
    "    #return [wide, ds_occurrenceICD10]\n",
    "    return [out_table, pid_survey]\n",
    "def assign_SES_healthins(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES or \"Dont Know\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"Yes\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"No\" in answer_SES:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_education(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"One Through Four\" in answer_SES or \"Five Through Eight\" in answer_SES or \"Nine Through Eleven\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Twelve Or GED\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"College One to Three\" in answer_SES:\n",
    "        return 2\n",
    "    elif \"College Graduate\" in answer_SES:\n",
    "        return 3\n",
    "    elif \"Advanced Degree\" in answer_SES:\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_income(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" 1585376,  → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "    if \"Prefer Not To Answer\" in answer_SES or \"Skip\" in answer_SES:\n",
    "        return np.nan\n",
    "    elif \"less 10k\" in answer_SES or \"10k 25k\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"25k 35k\" in answer_SES or \"35k 50k\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"50k 75k\" in answer_SES or \"75k 100k\" in answer_SES:\n",
    "        return 2\n",
    "    elif \"100k 150k\" in answer_SES or \"150k 200k\" in answer_SES:\n",
    "        return 3\n",
    "    elif \"more 200k\" in answer_SES:\n",
    "        return 4\n",
    "    else:\n",
    "        return np.nan\n",
    "def assign_SES_homeown(answer_SES):\n",
    "    \"\"\"\n",
    "    Given an education level (string), assign SES_education category based on the following scheme:\n",
    "    \n",
    "    - \"Prefer Not To Answer\" or \"Skip\" → np.nan\n",
    "    - \"One Through Four\", \"Five Through Eight\", \"Nine Through Eleven\" → 0\n",
    "    - \"Twelve or GED\" → 1\n",
    "    - \"College One to Three\" → 2\n",
    "    - \"College Graduate\" → 3\n",
    "    - \"Advanced Degree\" → 4\n",
    "    \"\"\"\n",
    "\n",
    "    if \"Current Home Own: Own\" in answer_SES:\n",
    "        return 1\n",
    "    elif \"Current Home Own: Rent\" in answer_SES:\n",
    "        return 0\n",
    "    elif \"Current Home Own: Other Arrangement\" in answer_SES:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in files\n",
    "\n",
    "ALL_IRD = getTable(\"ALL_IRD_raceproc.tsv\", \"personID_variant\")\n",
    "in_retdys = getTable(\"in_retdys.tsv\", \"personID_variant_concept\")\n",
    "notin_retdys = getTable(\"notin_retdys.tsv\", \"personID_variant_concept\")\n",
    "\n",
    "in_retdegen = getTable(\"in_retdegen.tsv\", \"personID_variant_concept\")\n",
    "notin_retdegen = getTable(\"notin_retdegen.tsv\", \"personID_variant_concept\")\n",
    "\n",
    "in_screenretdys = getTable(\"in_screenretdys.tsv\", \"personID_variant_concept\")\n",
    "notin_screenretdys = getTable(\"notin_screenretdys.tsv\", \"personID_variant_concept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#within genotype affected vs unaffected comparisons\n",
    "#get morbidities for each table\n",
    "in_retdys_result = pID_mobidity_master(in_retdys)\n",
    "in_retdys_matrix = in_retdys_result[0]\n",
    "in_retdys_full = in_retdys_result[1]\n",
    "in_retdys_full = in_retdys_full[~in_retdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "\n",
    "notin_retdys_result = pID_mobidity_master(notin_retdys)\n",
    "notin_retdys_matrix = notin_retdys_result[0]\n",
    "notin_retdys_full = notin_retdys_result[1]\n",
    "notin_retdys_full = notin_retdys_full[~notin_retdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "in_retdegen_result = pID_mobidity_master(in_retdegen)\n",
    "in_retdegen_matrix = in_retdegen_result[0]\n",
    "in_retdegen_full = in_retdegen_result[1]\n",
    "in_retdegen_full = in_retdegen_full[~in_retdegen_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "notin_retdegen_result = pID_mobidity_master(notin_retdegen)\n",
    "notin_retdegen_matrix = notin_retdegen_result[0]\n",
    "notin_retdegen_full = notin_retdegen_result[1]\n",
    "notin_retdegen_full = notin_retdegen_full[~notin_retdegen_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "in_screenretdys_result = pID_mobidity_master(in_screenretdys)\n",
    "in_screenretdys_matrix = in_screenretdys_result[0]\n",
    "in_screenretdys_full = in_screenretdys_result[1]\n",
    "in_screenretdys_full = in_screenretdys_full[~in_screenretdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]\n",
    "\n",
    "\n",
    "notin_screenretdys_result = pID_mobidity_master(notin_screenretdys)\n",
    "notin_screenretdys_matrix = notin_screenretdys_result[0]\n",
    "notin_screenretdys_full = notin_screenretdys_result[1]\n",
    "notin_screenretdys_full = notin_screenretdys_full[~notin_screenretdys_full.source_concept_code.isin(ScreenRetDysICD[[\"ICD_code\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate number of visits for each person\n",
    "def countVisits(matrix, df_visits):\n",
    "    visit_counts = (\n",
    "        df_visits\n",
    "        .groupby('person_id')['condition_start_datetime']\n",
    "        .size()\n",
    "        .reset_index(name='NumberOfVisits')\n",
    "    )\n",
    "    merged_matrix = pd.merge(matrix, visit_counts, on = \"person_id\", how = \"right\")\n",
    "    \n",
    "    return(merged_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e227ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_retdys_matrix = countVisits(in_retdys_matrix, in_retdys_full)\n",
    "in_retdegen_matrix = countVisits(in_retdegen_matrix, in_retdegen_full)\n",
    "in_screenretdys_matrix = countVisits(in_screenretdys_matrix, in_screenretdys_full)\n",
    "notin_retdys_matrix = countVisits(notin_retdys_matrix, notin_retdys_full)\n",
    "notin_retdegen_matrix = countVisits(notin_retdegen_matrix, notin_retdegen_full)\n",
    "notin_screenretdys_matrix = countVisits(notin_screenretdys_matrix, notin_screenretdys_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b42f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey data and SES\n",
    "in_retdys_survey = pID_survey_master(in_retdys)\n",
    "in_retdys_survey_matrix = in_retdys_survey[0]\n",
    "in_retdys_survey_full = in_retdys_survey[1]\n",
    "notin_retdys_survey = pID_survey_master(notin_retdys)\n",
    "notin_retdys_survey_matrix = notin_retdys_survey[0]\n",
    "notin_retdys_survey_full = notin_retdys_survey[1]\n",
    "\n",
    "in_retdegen_survey = pID_survey_master(in_retdegen)\n",
    "in_retdegen_survey_matrix = in_retdegen_survey[0]\n",
    "in_retdegen_survey_full = in_retdegen_survey[1]\n",
    "notin_retdegen_survey = pID_survey_master(notin_retdegen)\n",
    "notin_retdegen_survey_matrix = notin_retdegen_survey[0]\n",
    "notin_retdegen_survey_full = notin_retdegen_survey[1]\n",
    "\n",
    "in_screenretdys_survey = pID_survey_master(in_screenretdys)\n",
    "in_screenretdys_survey_matrix = in_screenretdys_survey[0]\n",
    "in_screenretdys_survey_full = in_screenretdys_survey[1]\n",
    "notin_screenretdys_survey = pID_survey_master(notin_screenretdys)\n",
    "notin_screenretdys_survey_matrix = notin_screenretdys_survey[0]\n",
    "notin_screenretdys_survey_full = notin_screenretdys_survey[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to merge survey/SES and morbidity data\n",
    "def mergeSurveyforAnno(matrix, source_df):\n",
    "    matrix[\"affected\"] = \"Yes\"\n",
    "    matrix = pd.merge(matrix, source_df[[\"person_id\", \"AgeAtVisit_Years\", \"sex_at_birth_source_value\", \"race\"]],\n",
    "                                      on=\"person_id\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "    matrix = matrix.rename(columns={'AgeAtVisit_Years': 'Age',\n",
    "                                                                 'sex_at_birth_source_value': \"Sex\"})\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def mergeSurveyforUNAnno(matrix, source_df):\n",
    "    matrix[\"affected\"] = \"No\"\n",
    "    matrix = pd.merge(matrix, source_df[[\"person_id\", \"AgeAtConsent_Years\", \"sex_at_birth_source_value\", \"race\"]],\n",
    "                                      on=\"person_id\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "    matrix = matrix.rename(columns={'AgeAtConsent_Years': 'Age',\n",
    "                                                                 'sex_at_birth_source_value': \"Sex\"})\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d258cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge survey/SES and morbidity data\n",
    "in_retdys_survey_matrix = mergeSurveyforAnno(in_retdys_survey[0], in_retdys)\n",
    "notin_retdys_survey_matrix = mergeSurveyforUNAnno(notin_retdys_survey[0], notin_retdys)\n",
    "in_retdegen_survey_matrix = mergeSurveyforAnno(in_retdegen_survey[0], in_retdegen)\n",
    "notin_retdegen_survey_matrix = mergeSurveyforUNAnno(notin_retdegen_survey[0], notin_retdegen)\n",
    "in_screenretdys_survey_matrix = mergeSurveyforAnno(in_screenretdys_survey[0], in_screenretdys)\n",
    "notin_screenretdys_survey_matrix = mergeSurveyforUNAnno(notin_screenretdys_survey[0], notin_screenretdys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare for logistic regression models\n",
    "\n",
    "#drop person_id\n",
    "retdys_matrix_merge_glmnet = retdys_matrix_merge.drop(\"person_id\", axis = 1)\n",
    "retdegen_matrix_merge_glmnet = retdegen_matrix_merge.drop(\"person_id\", axis = 1)\n",
    "screenretdys_matrix_merge_glmnet = screenretdys_matrix_merge.drop(\"person_id\", axis = 1)\n",
    "\n",
    "def makeSexNumeric(df):\n",
    "    sex_map = {\n",
    "        'SexAtBirth_Female': 0,\n",
    "        'SexAtBirth_Male':   1\n",
    "    }\n",
    "    \n",
    "    df['sex_numeric'] = df['Sex'].map(sex_map)\n",
    "    df['sex_numeric'] = df['sex_numeric'].astype(float)\n",
    "    df = df.drop(\"Sex\", axis = 1)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "retdys_matrix_merge_glmnet = makeSexNumeric(retdys_matrix_merge_glmnet)\n",
    "retdegen_matrix_merge_glmnet = makeSexNumeric(retdegen_matrix_merge_glmnet)\n",
    "screenretdys_matrix_merge_glmnet = makeSexNumeric(screenretdys_matrix_merge_glmnet)\n",
    "\n",
    "def dummyRace(df):\n",
    "    df = pd.get_dummies(df, columns=['race'], drop_first=True)\n",
    "    return df\n",
    "\n",
    "retdys_matrix_merge_glmnet = dummyRace(retdys_matrix_merge_glmnet)\n",
    "retdegen_matrix_merge_glmnet = dummyRace(retdegen_matrix_merge_glmnet)\n",
    "screenretdys_matrix_merge_glmnet = dummyRace(screenretdys_matrix_merge_glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c23c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_logit_result(result, html_path=None):\n",
    "    \"\"\"\n",
    "    Takes a fitted statsmodels LogitResults object (or a tuple where the second element is the LogitResults),\n",
    "    tidies and formats the coefficient table, and optionally writes an HTML file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    result : statsmodels.discrete.discrete_model.BinaryResults or tuple\n",
    "        If tuple, pass the (model, result) so use result[1]. Otherwise pass result directly.\n",
    "    html_path : str, optional\n",
    "        If provided, writes the HTML table to this file path.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    summary_df : pandas.DataFrame\n",
    "        Tidy table with Coefficient, Std. Error, OR, OR lower/upper, p-value, and significance stars.\n",
    "    html_table : str\n",
    "        String of the HTML table (border=0, index shown).\n",
    "    \"\"\"\n",
    "    # Extract the correct results object\n",
    "    res = result[1] if isinstance(result, (list, tuple)) else result\n",
    "    \n",
    "    # 1) Tidy the summary table\n",
    "    summary_df = res.summary2().tables[1].copy()\n",
    "    summary_df = summary_df.rename(columns={\n",
    "        'Coef.': 'Coefficient',\n",
    "        'Std.Err.': 'Std. Error',\n",
    "        '[0.025': 'CI Lower',\n",
    "        '0.975]': 'CI Upper',\n",
    "        'P>|z|': 'p-value'\n",
    "    })\n",
    "\n",
    "    # 2) Exponentiate coefficients for ORs\n",
    "    summary_df['OR']       = np.exp(summary_df['Coefficient'])\n",
    "    summary_df['OR lower'] = np.exp(summary_df['CI Lower'])\n",
    "    summary_df['OR upper'] = np.exp(summary_df['CI Upper'])\n",
    "\n",
    "    # 3) Add significance stars\n",
    "    def star(p):\n",
    "        if p < 0.001:\n",
    "            return '***'\n",
    "        elif p < 0.01:\n",
    "            return '**'\n",
    "        elif p < 0.05:\n",
    "            return '*'\n",
    "        else:\n",
    "            return ''\n",
    "    summary_df['signif'] = summary_df['p-value'].apply(star)\n",
    "\n",
    "    # 4) Format numeric columns\n",
    "    fmt_cols = ['Coefficient', 'Std. Error', 'CI Lower', 'CI Upper', 'p-value']\n",
    "    for col in fmt_cols:\n",
    "        summary_df[col] = summary_df[col].map(\"{:0.5f}\".format)\n",
    "\n",
    "    # 5) Reorder columns\n",
    "    summary_df = summary_df[['Coefficient', 'Std. Error', 'OR', 'OR lower', 'OR upper', 'p-value', 'signif']]\n",
    "\n",
    "    # 6) Generate HTML\n",
    "    html_table = summary_df.to_html(border=0, index=True, escape=False)\n",
    "\n",
    "    # 7) Optionally write to file\n",
    "    if html_path:\n",
    "        with open(html_path, 'w') as f:\n",
    "            f.write(html_table)\n",
    "\n",
    "    return summary_df, html_table\n",
    "\n",
    "\n",
    "def bin_outcome(df):    \n",
    "    df['outcome_bin'] = df['affected'].map({'Yes': 1, 'No': 0})\n",
    "    #df = df.drop(\"affected\", axis = 1)\n",
    "    return (df)\n",
    "def divideNumVisit(df, amt = 10):\n",
    "    df[\"NumberOfVisits\"] = df[\"NumberOfVisits\"] / amt\n",
    "    return df\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "def doLogit(df, drop_cols=None, divideNumVisits = 10):\n",
    "    \"\"\"\n",
    "    Fits a logistic regression and prints VIFs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "      Must contain 'outcome_bin' and whatever predictors you want.\n",
    "    drop_cols : list of str, optional\n",
    "      List of X-columns to drop before computing VIFs / fitting.\n",
    "    \"\"\"\n",
    "    # 1) Build X and y\n",
    "    X = df.drop(columns=['affected', 'outcome_bin'])\n",
    "    y = df['outcome_bin'].astype(float)\n",
    "    \n",
    "    # 2) Force numeric\n",
    "    #X = X.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "    \n",
    "    # 3) Clean infinities / NaNs\n",
    "\n",
    "    #X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    \n",
    "    # 5) Drop any user-specified columns in one go\n",
    "    if drop_cols:\n",
    "        X = X.drop(columns=drop_cols, errors='ignore')\n",
    "    \n",
    "    # after you’ve dropped columns, but before VIF:\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')   # convert any parsable column to numeric\n",
    "    X = X.astype(float)                            # ensure pure float dtype\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)       # push infs to NaN\n",
    "    \n",
    "\n",
    "    \n",
    "    if any(X.columns == \"NumberOfVisits\"):\n",
    "        X = divideNumVisit(X, amt = divideNumVisits)\n",
    "        \n",
    "    \n",
    "    # Combine predictors and outcome, then drop rows with NaNs\n",
    "    data = pd.concat([X, y], axis=1).dropna()\n",
    "    #data = pd.concat([X, y], axis=1)\n",
    "\n",
    "    # Separate back into X and y\n",
    "    X = data[X.columns]\n",
    "    y = data[y.name]\n",
    "\n",
    "\n",
    "    # Add constant for intercept\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    print(X.shape)\n",
    "    # 6) Compute VIFs\n",
    "    if X.shape[1] > 1:\n",
    "        vif_data = pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"VIF\": [\n",
    "                variance_inflation_factor(X.values, i)\n",
    "                for i in range(X.shape[1])\n",
    "            ]\n",
    "        })\n",
    "        print(vif_data)\n",
    "    \n",
    "    # 7) Fit the model\n",
    "    model = sm.Logit(y, X)\n",
    "    result = model.fit(disp=False)\n",
    "    return [model, result, X, y, data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076eac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retdys_matrix_merge_glmnet = bin_outcome(retdys_matrix_merge_glmnet)\n",
    "retdegen_matrix_merge_glmnet = bin_outcome(retdegen_matrix_merge_glmnet)\n",
    "screenretdys_matrix_merge_glmnet = bin_outcome(screenretdys_matrix_merge_glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns you want gone before VIF/model:\n",
    "# commented - keep\n",
    "# uncommented - drop\n",
    "to_drop = [\n",
    "    'comorbidities_vitAdef',\n",
    "    'comorb_GI_skin_MSK_GU',\n",
    "\n",
    "    'comordbities_dactyly',\n",
    "    'comordbities_external',\n",
    "    'comordbities_congenital',\n",
    "    'comordbities_neuropsych',\n",
    "    'comordbities_ent',\n",
    "    'comordbities_rare',\n",
    "    'cmspec_DM_microvascular',\n",
    "    'comordbities_circulatory',\n",
    "    'comordbities_ischemicHD',\n",
    "    'comorbidities_hemonc',\n",
    "    'race_WhatRaceEthnicity_Black',\n",
    "    'race_Unknown',\n",
    "    'race_WhatRaceEthnicity_AIAN',\n",
    "    'race_WhatRaceEthnicity_MENA',\n",
    "    #'race_WhatRaceEthnicity_White',\n",
    "    #'SES_education',\n",
    "    #'SES_income',\n",
    "    #'SES_homeown',\n",
    "    'SES_healthins',\n",
    "    #'SES_married',\n",
    "    #'comorbidities_DM',\n",
    "    #'comordbities_obesity',\n",
    "    #'comordbities_HTN',\n",
    "    #'comorbidities_HLD',\n",
    "    #'LS_smoke',\n",
    "    #'NumberOfVisits',\n",
    "    #'sex_numeric',\n",
    "    'race_WhatRaceEthnicity_Asian'\n",
    "    \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression for IRD set, changing the dataframe and to_drop as needed\n",
    "result = doLogit(retdys_matrix_merge_glmnet, drop_cols=to_drop, divideNumVisits = 100)\n",
    "print(result[1].summary())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
